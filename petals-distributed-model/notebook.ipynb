{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from petals import AutoDistributedModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d4aec09c52428ca9456dbfc0b7a4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfd939199624a8c866d42b0c5e76ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b40fa2ced82494f92ba6df138415edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6667964f6fa1444793a2e84274db661e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 05 15:42:09.023 [\u001b[1m\u001b[34mINFO\u001b[0m] Make sure you follow the Llama terms of use: https://llama.meta.com/llama3/license, https://llama.meta.com/llama2/license\n",
      "Sep 05 15:42:09.024 [\u001b[1m\u001b[34mINFO\u001b[0m] Using DHT prefix: Meta-Llama-3-1-405B-Instruct-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5f92f85ed149609a0052fe53f95b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/94.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d441b8e62248218dde9ceee0396d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e60b8fe624f4e68bdc8982131c2090c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00191.safetensors:   0%|          | 0.00/4.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmeta-llama/Meta-Llama-3.1-405B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = AutoDistributedModelForCausalLM.from_pretrained(model_name, initial_peers=INITIAL_PEERS)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/petals/utils/auto_config.py:79\u001b[39m, in \u001b[36mDefaultRevisionMixin.from_pretrained\u001b[39m\u001b[34m(cls, model_name_or_path, revision, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     revision = \u001b[38;5;28mcls\u001b[39m.DEFAULT_REVISIONS[model_name_or_path]\n\u001b[32m     78\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, revision \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().from_pretrained(model_name_or_path, *args, revision=revision, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/petals/utils/auto_config.py:52\u001b[39m, in \u001b[36m_AutoDistributedBase.from_pretrained\u001b[39m\u001b[34m(cls, model_name_or_path, *args, **kwargs)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proper_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPetals does not have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for model type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.model_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proper_cls.from_pretrained(model_name_or_path, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/petals/client/from_pretrained.py:31\u001b[39m, in \u001b[36mFromPretrainedMixin.from_pretrained\u001b[39m\u001b[34m(cls, model_name_or_path, low_cpu_mem_usage, *args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m     low_cpu_mem_usage = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ignore_keys(\u001b[38;5;28mcls\u001b[39m._keys_to_ignore_on_load_unexpected):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().from_pretrained(model_name_or_path, *args, low_cpu_mem_usage=low_cpu_mem_usage, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/transformers/modeling_utils.py:3658\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[32m   3656\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[32m   3657\u001b[39m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3658\u001b[39m     resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n\u001b[32m   3659\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   3660\u001b[39m         resolved_archive_file,\n\u001b[32m   3661\u001b[39m         cache_dir=cache_dir,\n\u001b[32m   3662\u001b[39m         force_download=force_download,\n\u001b[32m   3663\u001b[39m         proxies=proxies,\n\u001b[32m   3664\u001b[39m         resume_download=resume_download,\n\u001b[32m   3665\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   3666\u001b[39m         token=token,\n\u001b[32m   3667\u001b[39m         user_agent=user_agent,\n\u001b[32m   3668\u001b[39m         revision=revision,\n\u001b[32m   3669\u001b[39m         subfolder=subfolder,\n\u001b[32m   3670\u001b[39m         _commit_hash=commit_hash,\n\u001b[32m   3671\u001b[39m     )\n\u001b[32m   3673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3674\u001b[39m     is_safetensors_available()\n\u001b[32m   3675\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   3676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file.endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3677\u001b[39m ):\n\u001b[32m   3678\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/petals/client/from_pretrained.py:80\u001b[39m, in \u001b[36mpatched_get_checkpoint_shard_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, index_filename, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(index_filename, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     78\u001b[39m         json.dump(index, f)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m original_get_checkpoint_shard_files(pretrained_model_name_or_path, index_filename, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/transformers/utils/hub.py:1079\u001b[39m, in \u001b[36mget_checkpoint_shard_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading shards\u001b[39m\u001b[33m\"\u001b[39m, disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1078\u001b[39m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m         cached_filename = cached_file(\n\u001b[32m   1080\u001b[39m             pretrained_model_name_or_path,\n\u001b[32m   1081\u001b[39m             shard_filename,\n\u001b[32m   1082\u001b[39m             cache_dir=cache_dir,\n\u001b[32m   1083\u001b[39m             force_download=force_download,\n\u001b[32m   1084\u001b[39m             proxies=proxies,\n\u001b[32m   1085\u001b[39m             resume_download=resume_download,\n\u001b[32m   1086\u001b[39m             local_files_only=local_files_only,\n\u001b[32m   1087\u001b[39m             token=token,\n\u001b[32m   1088\u001b[39m             user_agent=user_agent,\n\u001b[32m   1089\u001b[39m             revision=revision,\n\u001b[32m   1090\u001b[39m             subfolder=subfolder,\n\u001b[32m   1091\u001b[39m             _commit_hash=_commit_hash,\n\u001b[32m   1092\u001b[39m         )\n\u001b[32m   1093\u001b[39m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[32m   1094\u001b[39m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/transformers/utils/hub.py:402\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m user_agent = http_user_agent(user_agent)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    401\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     resolved_file = hf_hub_download(\n\u001b[32m    403\u001b[39m         path_or_repo_id,\n\u001b[32m    404\u001b[39m         filename,\n\u001b[32m    405\u001b[39m         subfolder=\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[32m    406\u001b[39m         repo_type=repo_type,\n\u001b[32m    407\u001b[39m         revision=revision,\n\u001b[32m    408\u001b[39m         cache_dir=cache_dir,\n\u001b[32m    409\u001b[39m         user_agent=user_agent,\n\u001b[32m    410\u001b[39m         force_download=force_download,\n\u001b[32m    411\u001b[39m         proxies=proxies,\n\u001b[32m    412\u001b[39m         resume_download=resume_download,\n\u001b[32m    413\u001b[39m         token=token,\n\u001b[32m    414\u001b[39m         local_files_only=local_files_only,\n\u001b[32m    415\u001b[39m     )\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    417\u001b[39m     resolved_file = _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[32m   1011\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m   1012\u001b[39m         cache_dir=cache_dir,\n\u001b[32m   1013\u001b[39m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[32m   1014\u001b[39m         repo_id=repo_id,\n\u001b[32m   1015\u001b[39m         filename=filename,\n\u001b[32m   1016\u001b[39m         repo_type=repo_type,\n\u001b[32m   1017\u001b[39m         revision=revision,\n\u001b[32m   1018\u001b[39m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[32m   1019\u001b[39m         endpoint=endpoint,\n\u001b[32m   1020\u001b[39m         etag_timeout=etag_timeout,\n\u001b[32m   1021\u001b[39m         headers=hf_headers,\n\u001b[32m   1022\u001b[39m         proxies=proxies,\n\u001b[32m   1023\u001b[39m         token=token,\n\u001b[32m   1024\u001b[39m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[32m   1025\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1026\u001b[39m         force_download=force_download,\n\u001b[32m   1027\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:1073\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(\n\u001b[32m   1074\u001b[39m     repo_id=repo_id,\n\u001b[32m   1075\u001b[39m     filename=filename,\n\u001b[32m   1076\u001b[39m     repo_type=repo_type,\n\u001b[32m   1077\u001b[39m     revision=revision,\n\u001b[32m   1078\u001b[39m     endpoint=endpoint,\n\u001b[32m   1079\u001b[39m     proxies=proxies,\n\u001b[32m   1080\u001b[39m     etag_timeout=etag_timeout,\n\u001b[32m   1081\u001b[39m     headers=headers,\n\u001b[32m   1082\u001b[39m     token=token,\n\u001b[32m   1083\u001b[39m     local_files_only=local_files_only,\n\u001b[32m   1084\u001b[39m     storage_folder=storage_folder,\n\u001b[32m   1085\u001b[39m     relative_filename=relative_filename,\n\u001b[32m   1086\u001b[39m )\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m         metadata = get_hf_file_metadata(\n\u001b[32m   1547\u001b[39m             url=url, proxies=proxies, timeout=etag_timeout, headers=headers, token=token, endpoint=endpoint\n\u001b[32m   1548\u001b[39m         )\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1550\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1551\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1460\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = _request_wrapper(\n\u001b[32m   1464\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mHEAD\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1465\u001b[39m     url=url,\n\u001b[32m   1466\u001b[39m     headers=hf_headers,\n\u001b[32m   1467\u001b[39m     allow_redirects=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1468\u001b[39m     follow_relative_redirects=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1469\u001b[39m     proxies=proxies,\n\u001b[32m   1470\u001b[39m     timeout=timeout,\n\u001b[32m   1471\u001b[39m )\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1474\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = _request_wrapper(\n\u001b[32m    287\u001b[39m         method=method,\n\u001b[32m    288\u001b[39m         url=url,\n\u001b[32m    289\u001b[39m         follow_relative_redirects=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    290\u001b[39m         **params,\n\u001b[32m    291\u001b[39m     )\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = session.request(method=method, url=url, **kwargs)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/requests/sessions.py:575\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[32m    563\u001b[39m req = Request(\n\u001b[32m    564\u001b[39m     method=method.upper(),\n\u001b[32m    565\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     hooks=hooks,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m prep = \u001b[38;5;28mself\u001b[39m.prepare_request(req)\n\u001b[32m    577\u001b[39m proxies = proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    579\u001b[39m settings = \u001b[38;5;28mself\u001b[39m.merge_environment_settings(\n\u001b[32m    580\u001b[39m     prep.url, proxies, stream, verify, cert\n\u001b[32m    581\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/requests/sessions.py:481\u001b[39m, in \u001b[36mSession.prepare_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    479\u001b[39m auth = request.auth\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trust_env \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auth \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auth:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     auth = get_netrc_auth(request.url)\n\u001b[32m    483\u001b[39m p = PreparedRequest()\n\u001b[32m    484\u001b[39m p.prepare(\n\u001b[32m    485\u001b[39m     method=request.method.upper(),\n\u001b[32m    486\u001b[39m     url=request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m     hooks=merge_hooks(request.hooks, \u001b[38;5;28mself\u001b[39m.hooks),\n\u001b[32m    497\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/LLMHub/lib/python3.11/site-packages/requests/utils.py:223\u001b[39m, in \u001b[36mget_netrc_auth\u001b[39m\u001b[34m(url, raise_errors)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m netrc_locations:\n\u001b[32m    222\u001b[39m     loc = os.path.expanduser(f)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(loc):\n\u001b[32m    224\u001b[39m         netrc_path = loc\n\u001b[32m    225\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:19\u001b[39m, in \u001b[36mexists\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "INITIAL_PEERS = [\n",
    "    \"/ip4/10.52.88.17/tcp/31310/p2p/Qmf8KYztHEGesmmqMbjK8DEwD1NWAgk9jHNekK62qFjZVT\",\n",
    "    \"/ip4/10.52.88.40/tcp/31310/p2p/QmdcQg1qEFJD8K5daEBqWCahW2Xdd1g13v58NwthPWgNN5\"\n",
    "]\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-405B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoDistributedModelForCausalLM.from_pretrained(model_name, initial_peers=INITIAL_PEERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the model as if it were on your computer\n",
    "inputs = tokenizer(\"A cat sat\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "outputs = model.generate(inputs, max_new_tokens=5)\n",
    "print(tokenizer.decode(outputs[0])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMHub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
